{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a32f0432",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b1662d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhanghudong/miniconda3/envs/zhd/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoConfig\n",
    "model_path = \"qwen-1.5b\"\n",
    "config = AutoConfig.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a2f4ff4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qwen2Config {\n",
       "  \"architectures\": [\n",
       "    \"Qwen2ForCausalLM\"\n",
       "  ],\n",
       "  \"attention_dropout\": 0.0,\n",
       "  \"bos_token_id\": 151643,\n",
       "  \"dtype\": \"bfloat16\",\n",
       "  \"eos_token_id\": 151643,\n",
       "  \"hidden_act\": \"silu\",\n",
       "  \"hidden_size\": 1536,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 8960,\n",
       "  \"layer_types\": [\n",
       "    \"full_attention\",\n",
       "    \"full_attention\",\n",
       "    \"full_attention\",\n",
       "    \"full_attention\",\n",
       "    \"full_attention\",\n",
       "    \"full_attention\",\n",
       "    \"full_attention\",\n",
       "    \"full_attention\",\n",
       "    \"full_attention\",\n",
       "    \"full_attention\",\n",
       "    \"full_attention\",\n",
       "    \"full_attention\",\n",
       "    \"full_attention\",\n",
       "    \"full_attention\",\n",
       "    \"full_attention\",\n",
       "    \"full_attention\",\n",
       "    \"full_attention\",\n",
       "    \"full_attention\",\n",
       "    \"full_attention\",\n",
       "    \"full_attention\",\n",
       "    \"full_attention\",\n",
       "    \"full_attention\",\n",
       "    \"full_attention\",\n",
       "    \"full_attention\",\n",
       "    \"full_attention\",\n",
       "    \"full_attention\",\n",
       "    \"full_attention\",\n",
       "    \"full_attention\"\n",
       "  ],\n",
       "  \"max_position_embeddings\": 131072,\n",
       "  \"max_window_layers\": 28,\n",
       "  \"model_type\": \"qwen2\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 28,\n",
       "  \"num_key_value_heads\": 2,\n",
       "  \"rms_norm_eps\": 1e-06,\n",
       "  \"rope_scaling\": null,\n",
       "  \"rope_theta\": 1000000.0,\n",
       "  \"sliding_window\": null,\n",
       "  \"tie_word_embeddings\": true,\n",
       "  \"transformers_version\": \"4.57.0\",\n",
       "  \"use_cache\": true,\n",
       "  \"use_mrope\": false,\n",
       "  \"use_sliding_window\": false,\n",
       "  \"vocab_size\": 151936\n",
       "}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62f925d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qwen2ForCausalLM(\n",
       "  (model): Qwen2Model(\n",
       "    (embed_tokens): Embedding(151936, 1536)\n",
       "    (layers): ModuleList(\n",
       "      (0-27): 28 x Qwen2DecoderLayer(\n",
       "        (self_attn): Qwen2Attention(\n",
       "          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "          (k_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
       "          (v_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
       "          (o_proj): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "        )\n",
       "        (mlp): Qwen2MLP(\n",
       "          (gate_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "          (up_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "          (down_proj): Linear(in_features=8960, out_features=1536, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "    (rotary_emb): Qwen2RotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1536, out_features=151936, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 从零初始化的模型\n",
    "from transformers import AutoModelForCausalLM\n",
    "model = AutoModelForCausalLM.from_config(config, trust_remote_code=True)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7851ebae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qwen2ForCausalLM(\n",
       "  (model): Qwen2Model(\n",
       "    (embed_tokens): Embedding(151936, 1536)\n",
       "    (layers): ModuleList(\n",
       "      (0-27): 28 x Qwen2DecoderLayer(\n",
       "        (self_attn): Qwen2Attention(\n",
       "          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "          (k_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
       "          (v_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
       "          (o_proj): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "        )\n",
       "        (mlp): Qwen2MLP(\n",
       "          (gate_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "          (up_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "          (down_proj): Linear(in_features=8960, out_features=1536, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "    (rotary_emb): Qwen2RotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1536, out_features=151936, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加载预训练模型\n",
    "from transformers import AutoModelForCausalLM\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87d40976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qwen2TokenizerFast(name_or_path='qwen-1.5b', vocab_size=151643, model_max_length=131072, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|endoftext|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n",
       "\t151643: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151644: AddedToken(\"<|im_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151645: AddedToken(\"<|im_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151646: AddedToken(\"<|object_ref_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151647: AddedToken(\"<|object_ref_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151648: AddedToken(\"<|box_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151649: AddedToken(\"<|box_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151650: AddedToken(\"<|quad_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151651: AddedToken(\"<|quad_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151652: AddedToken(\"<|vision_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151653: AddedToken(\"<|vision_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151654: AddedToken(\"<|vision_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151655: AddedToken(\"<|image_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151656: AddedToken(\"<|video_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151657: AddedToken(\"<tool_call>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151658: AddedToken(\"</tool_call>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151659: AddedToken(\"<|fim_prefix|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151660: AddedToken(\"<|fim_middle|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151661: AddedToken(\"<|fim_suffix|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151662: AddedToken(\"<|fim_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151663: AddedToken(\"<|repo_name|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151664: AddedToken(\"<|file_sep|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "}\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加载预训练好的tokenizer\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd77d6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "ds = load_dataset('json', data_files='/data/zhanghudong/dataset/mobvoi_seq_monkey_general_open_corpus.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4356991f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 13000000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33b6ec59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': '在查处虚开增值税专用发票案件中，常常涉及进项留抵税额和税款损失的认定和处理。在计算税款损失时，要不要将进项留抵税额包括在内？\\n对此，实务中存在意见分歧。\\n有人主张归并，即计算税款损失时包括进项留抵税额；\\n有人主张剥离，即计算税款损失时剔除进项留抵税额。分析这个问题，需要确定进项留抵税额与税款损失之间是什么关系。\\n理清这二者之间的关系，首先需要了解增值税的概念和其抵扣机制。增值税是以商品（货物、服务等）在流转过程中产生的增值额作为计税依据而征收的一种流转税。为避免重复征税，在增值税中存在抵扣链条机制。\\n一般而言，交易上游企业缴纳的税额，交易下游企业可以对相应的税额进行抵扣。\\n对增值税一般纳税人来说，其购进货物、服务等取得增值税专用发票，发票上的税额是进项税额。\\n其出售货物、服务等，向购买方开具增值税专用发票，发票的税额是销项税额。\\n一般情况下，销项税额减去进项税额的金额是应纳税额，企业根据应纳税额按期申报纳税。\\n其次需要了解进项留抵税额的概念及产生原因。\\n在计算销项税额和进项税额的差额时，有时会出现负数，即当期进项税额大于当期销项税额。这个差额在当期未实现抵扣，为进项留抵税额，在以后纳税人有销项税额时再进行抵扣。\\n企业产生进项留抵税额的主要原因是其进项税额和销项税额时间上的不一致。\\n例如，企业前期集中采购货物和服务，投资大，销项税率低于进项税率等。\\n从税款抵扣的角度看，进项留抵税额只是购进的这部分进项税额参与到增值税应纳税额的计算过程中，但是其对应的进项税额抵扣还未真正实现，一般要等到其未来有相应的销项税额时，才能真正实现进项税额抵扣。\\n可见，进项留抵税额处于不确定状态，能否抵扣受到很多因素影响，例如企业经营中断，没有销项税额，这时进项留抵税额就无法实现抵扣。但如果企业按照税收政策规定申请进项留抵退税，进项税额抵扣就随之实现。\\n最后需要了解税款损失的概念。\\n税款损失，通常是指因虚开增值税专用发票，导致国家税款被骗或者流失的金额。关于税款损失，实务中有多种表述。\\n例如，北京大学法学院教授陈兴良曾谈到虚开行为本身不会造成国家税款损失，只有利用发票抵扣时才会造成国家税款损失。刘兵等编著的《虚开增值税专用发票案例司法观点和案例解析》一书中提到：“给国家税款造成损失的数额，实际上就是被骗取的国家税款在侦查终结以前无法追回的部分。”\\n赵清海与王家欣合著的《增值税专用发票虚开的判定与预防》一书中提到：“司法实践中，受票方用虚开的增值税专用发票予以抵扣的税款，从而导致受票方应纳税额的减少是法院所认定的国家税款流失的金额。”\\n从这些表述可见，税款损失应该是实际造成的损失，不应包括不确定的部分——进项留抵税额，进项留抵税额与税款损失之间不能直接画等号。\\n综上分析，进项留抵税额，只是使国家税款处于可能被抵扣的状态，还没有真正造成国家税款流失，一般情况下应将其从税款损失中剥离，特殊条件下将其归并入税款损失。\\n例如，当纳税人造假按照税收政策规定申请进项留抵税额退税后，有关税款损失将会从危险状态转化成危害结果，这时候要将有关进项留抵税额并入税款损失。\\n所以，在虚开增值税专用发票案件中，一般情况下，如果以纳税人的进项税额作为税款损失的计算基数，在对其进行行政处罚或刑事处罚时，应把进项留抵税额从税款损失中剔除，但纳税人申请进项留抵退税的除外。这样处理，把处罚与危害结果相对应，体现行政处罚法的过罚相当原则和刑法的罚当其罪原则。'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e6a2ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids\n",
      "attention_mask\n"
     ]
    }
   ],
   "source": [
    "for key in tokenizer(ds['train'][0]['text']).keys():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a7fb7f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['text']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names = list(ds[\"train\"].features)\n",
    "column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb807c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    output = tokenizer([item for item in examples[\"text\"]])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21c3b56c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[18493], [32876], [44290], [100226], [29767], [49185], [25511], [84088], [95411], [11622], [28291], [94444], [80642], [14224], [15946], [3837], [38953], [38953], [100068], [81217], [41299], [47882], [99337], [99990], [84088], [61191], [33108], [84088], [68153], [99644], [20726], [9370], [28951], [22382], [33108], [44290], [21887], [1773], [18493], [37643], [69103], [84088], [68153], [99644], [20726], [13343], [3837], [30534], [16530], [30534], [44063], [41299], [47882], [99337], [99990], [84088], [61191], [67279], [100139], [18493], [31843], [11319], [198], [32664], [31991], [3837], [39973], [31952], [15946], [24360], [18493], [36589], [88970], [17177], [101802], [1773], [198], [18830], [17340], [35568], [86341], [100040], [62926], [3837], [91676], [37643], [69103], [84088], [68153], [99644], [20726], [13343], [67279], [100139], [41299], [47882], [99337], [99990], [84088], [61191], [24968], [198], [18830], [17340], [35568], [86341], [101819], [99372], [3837], [91676], [37643], [69103], [84088], [68153], [99644], [20726], [13343], [103869], [20755], [41299], [47882], [99337], [99990], [84088], [61191], [1773], [17177], [97771], [43288], [18947], [56007], [33872], [3837], [58362], [30534], [33956], [22382], [41299], [47882], [99337], [99990], [84088], [61191], [57218], [84088], [68153], [99644], [20726], [53930], [17881], [20412], [99217], [81596], [29256], [38176], [1773], [198], [21887], [79766], [43288], [40820], [28946], [53930], [17881], [9370], [29256], [38176], [3837], [59975], [60726], [58362], [30534], [34187], [49238], [49185], [25511], [84088], [9370], [99706], [99376], [33108], [41146], [99990], [100837], [32648], [43316], [1773], [49185], [25511], [84088], [20412], [23031], [32022], [24442], [9909], [81668], [52853], [5373], [43209], [31952], [49567], [7552], [18493], [88653], [46670], [38182], [38507], [15946], [51232], [21287], [9370], [49185], [25511], [61191], [19403], [17714], [37643], [84088], [99539], [16038], [68536], [99543], [50009], [9370], [14777], [86402], [88653], [46670], [84088], [1773], [17714], [99753], [99506], [29258], [58364], [99543], [84088], [3837], [18493], [49185], [25511], [84088], [15946], [24360], [18493], [99990], [100837], [63314], [38989], [32648], [43316], [1773], [198], [14777], [99791], [68536], [77144], [3837], [38109], [86744], [17447], [82894], [97797], [40952], [101439], [99458], [9370], [84088], [61191], [3837], [38109], [86744], [16872], [82894], [97797], [40952], [30440], [23031], [32664], [48921], [50511], [9370], [84088], [61191], [41299], [22243], [99990], [100837], [1773], [198], [32664], [49185], [25511], [84088], [14777], [99791], [99458], [84088], [17340], [36407], [36587], [3837], [41146], [77172], [41299], [81668], [52853], [5373], [43209], [31952], [49567], [18158], [49828], [49185], [25511], [84088], [95411], [11622], [28291], [94444], [3837], [28291], [94444], [17447], [9370], [84088], [61191], [20412], [41299], [47882], [84088], [61191], [1773], [198], [41146], [20221], [99429], [81668], [52853], [5373], [43209], [31952], [49567], [3837], [69041], [77172], [99565], [23384], [29767], [76813], [49185], [25511], [84088], [95411], [11622], [28291], [94444], [3837], [28291], [94444], [9370], [84088], [61191], [20412], [91453], [47882], [84088], [61191], [1773], [198], [14777], [99791], [39374], [99384], [16872], [3837], [91453], [47882], [84088], [61191], [99536], [85336], [41299], [47882], [84088], [61191], [9370], [34230], [61191], [20412], [50511], [99458], [84088], [61191], [3837], [97797], [40952], [99408], [16038], [50511], [99458], [84088], [61191], [59879], [22704], [99809], [42278], [99458], [84088], [1773], [198], [41146], [32571], [58362], [30534], [34187], [49238], [41299], [47882], [99337], [99990], [84088], [61191], [9370], [99706], [99376], [81217], [51232], [21287], [52129], [62112], [1773], [198], [18493], [37643], [69103], [91453], [47882], [84088], [61191], [33108], [41299], [47882], [84088], [61191], [9370], [99572], [61191], [13343], [3837], [18830], [13343], [36993], [20221], [46451], [99393], [8863], [3837], [91676], [39165], [22704], [41299], [47882], [84088], [61191], [26288], [34204], [39165], [22704], [91453], [47882], [84088], [61191], [1773], [43288], [18947], [99572], [61191], [18493], [39165], [22704], [38342], [39973], [46451], [99990], [100837], [3837], [17714], [41299], [47882], [99337], [99990], [84088], [61191], [3837], [18493], [23031], [33447], [99458], [84088], [17340], [18830], [91453], [47882], [84088], [61191], [13343], [87256], [41299], [22243], [99990], [100837], [1773], [198], [97797], [40952], [51232], [21287], [41299], [47882], [99337], [99990], [84088], [61191], [9370], [35568], [30534], [52129], [62112], [20412], [41146], [41299], [47882], [84088], [61191], [33108], [91453], [47882], [84088], [61191], [13343], [17881], [17447], [9370], [16530], [14777], [99299], [1773], [198], [26355], [29524], [3837], [97797], [40952], [24562], [22704], [42067], [15946], [99433], [77172], [81668], [52853], [33108], [43209], [31952], [3837], [79072], [51125], [26288], [3837], [91453], [47882], [84088], [95355], [99285], [34204], [41299], [47882], [84088], [95355], [49567], [1773], [198], [45181], [84088], [68153], [99990], [100837], [9370], [63836], [26381], [50930], [3837], [41299], [47882], [99337], [99990], [84088], [61191], [91680], [20412], [77172], [41299], [9370], [43288], [32948], [17177], [41299], [47882], [84088], [61191], [73743], [57218], [26939], [49185], [25511], [84088], [50511], [99458], [84088], [61191], [9370], [37643], [69103], [38182], [38507], [15946], [3837], [77288], [20412], [41146], [32664], [50511], [9370], [41299], [47882], [84088], [61191], [99990], [100837], [97706], [38342], [88051], [36556], [39973], [46451], [3837], [14777], [99791], [30534], [49567], [26939], [41146], [38342], [36407], [18830], [48921], [50511], [9370], [91453], [47882], [84088], [61191], [13343], [3837], [99306], [26232], [88051], [36556], [39973], [46451], [41299], [47882], [84088], [61191], [99990], [100837], [1773], [198], [30440], [88970], [3837], [41299], [47882], [99337], [99990], [84088], [61191], [44290], [34204], [16530], [33956], [22382], [99762], [35243], [3837], [26232], [32376], [99990], [100837], [99204], [26939], [99165], [42140], [62112], [71138], [57222], [99365], [3837], [26355], [29524], [97797], [40952], [53393], [99209], [15946], [63789], [3837], [70927], [18830], [91453], [47882], [84088], [61191], [3837], [43288], [13343], [41299], [47882], [99337], [99990], [84088], [61191], [80158], [42192], [24339], [39973], [46451], [99990], [100837], [1773], [77288], [29524], [27773], [97797], [40952], [59879], [99331], [84088], [50009], [74413], [99560], [74386], [22382], [99809], [14880], [41299], [47882], [99337], [99990], [55806], [84088], [3837], [41299], [47882], [84088], [61191], [99990], [100837], [80158], [99411], [53930], [39973], [46451], [1773], [198], [31235], [33447], [58362], [30534], [34187], [49238], [84088], [68153], [99644], [20726], [9370], [99706], [99376], [1773], [198], [84088], [68153], [99644], [20726], [3837], [31935], [38953], [20412], [63367], [62112], [100226], [29767], [49185], [25511], [84088], [95411], [11622], [28291], [94444], [3837], [64720], [99299], [28404], [45629], [84088], [68153], [99250], [100117], [57191], [28946], [88653], [20726], [9370], [34230], [61191], [1773], [29256], [34204], [84088], [68153], [99644], [20726], [3837], [39973], [31952], [15946], [18830], [42140], [86402], [20742], [41932], [1773], [198], [26355], [29524], [3837], [48309], [46553], [26288], [47764], [24339], [47764], [93823], [99182], [99942], [100348], [99355], [99584], [99798], [99437], [26939], [100226], [29767], [22243], [17714], [21894], [95256], [16530], [36993], [66078], [12857], [28404], [45629], [84088], [68153], [99644], [20726], [3837], [91680], [18830], [59532], [11622], [28291], [94444], [99990], [100837], [13343], [99306], [36993], [66078], [12857], [28404], [45629], [84088], [68153], [99644], [20726], [1773], [100351], [99807], [49567], [30868], [99610], [9370], [26940], [100226], [29767], [49185], [25511], [84088], [95411], [11622], [28291], [94444], [80642], [26355], [64643], [24339], [99237], [27442], [33108], [80642], [26355], [49238], [97771], [25067], [14777], [90286], [15946], [28072], [26939], [5122], [2073], [89012], [28404], [45629], [84088], [68153], [66078], [12857], [99644], [20726], [9370], [8863], [61191], [3837], [39973], [99326], [17447], [80158], [20412], [99250], [100117], [18158], [9370], [28404], [45629], [84088], [68153], [18493], [100613], [32876], [99501], [36885], [23031], [24562], [42192], [24339], [99626], [18397], [9370], [32948], [17177], [1773], [854], [198], [103959], [79766], [55135], [57218], [99445], [45629], [100885], [39762], [99610], [9370], [26940], [49185], [25511], [84088], [95411], [11622], [28291], [94444], [100226], [29767], [9370], [99713], [22382], [57218], [98841], [99287], [25067], [14777], [90286], [15946], [28072], [26939], [5122], [2073], [64643], [24339], [39973], [100051], [15946], [3837], [99204], [94444], [23384], [11622], [100226], [29767], [9370], [49185], [25511], [84088], [95411], [11622], [28291], [94444], [99944], [23031], [99990], [100837], [9370], [84088], [68153], [3837], [45181], [68536], [64720], [99299], [99204], [94444], [23384], [50511], [99458], [84088], [61191], [9370], [99536], [82647], [20412], [24339], [93823], [31838], [28951], [22382], [9370], [28404], [45629], [84088], [68153], [88653], [20726], [9370], [34230], [61191], [1773], [854], [198], [45181], [43288], [97084], [20742], [41932], [30440], [88970], [3837], [84088], [68153], [99644], [20726], [50511], [75882], [20412], [39973], [99326], [66078], [12857], [9370], [99644], [20726], [3837], [16530], [50511], [67279], [100139], [16530], [33956], [22382], [9370], [32948], [17177], [2293], [2293], [41299], [47882], [99337], [99990], [84088], [61191], [3837], [41299], [47882], [99337], [99990], [84088], [61191], [57218], [84088], [68153], [99644], [20726], [53930], [17881], [16530], [26232], [73145], [29077], [54623], [49567], [17992], [1773], [198], [99611], [17447], [17177], [97771], [3837], [41299], [47882], [99337], [99990], [84088], [61191], [3837], [91680], [20412], [32555], [28404], [45629], [84088], [68153], [44290], [34204], [30440], [26232], [99250], [99990], [100837], [9370], [99762], [35243], [3837], [97706], [70927], [18830], [88051], [36556], [66078], [12857], [28404], [45629], [84088], [68153], [88653], [20726], [3837], [14777], [99791], [39374], [99384], [16872], [50511], [44063], [41146], [45181], [84088], [68153], [99644], [20726], [15946], [101819], [99372], [3837], [65278], [100747], [38989], [14224], [16872], [44063], [41146], [100040], [62926], [17254], [84088], [68153], [99644], [20726], [1773], [198], [26355], [29524], [3837], [39165], [99458], [84088], [17340], [66078], [99436], [59879], [99331], [84088], [50009], [74413], [99560], [74386], [22382], [99809], [14880], [41299], [47882], [99337], [99990], [84088], [61191], [55806], [84088], [33447], [3837], [18830], [29256], [84088], [68153], [99644], [20726], [44063], [36993], [45181], [100087], [99567], [99762], [35243], [46670], [32108], [12857], [100087], [99441], [36885], [27773], [3837], [43288], [13343], [99383], [30534], [44063], [18830], [29256], [41299], [47882], [99337], [99990], [84088], [61191], [62926], [17254], [84088], [68153], [99644], [20726], [1773], [198], [31838], [23031], [3837], [18493], [100226], [29767], [49185], [25511], [84088], [95411], [11622], [28291], [94444], [80642], [14224], [15946], [3837], [14777], [99791], [39374], [99384], [16872], [3837], [29524], [27773], [23031], [99458], [84088], [17340], [9370], [41299], [47882], [84088], [61191], [19403], [17714], [84088], [68153], [99644], [20726], [9370], [37643], [69103], [74046], [8863], [3837], [18493], [32664], [41146], [41299], [22243], [22243], [74413], [44290], [100554], [57191], [99867], [29826], [44290], [100554], [13343], [3837], [50511], [99360], [41299], [47882], [99337], [99990], [84088], [61191], [45181], [84088], [68153], [99644], [20726], [15946], [103869], [20755], [3837], [77288], [99458], [84088], [17340], [99809], [14880], [41299], [47882], [99337], [99990], [55806], [84088], [9370], [20755], [47815], [1773], [43288], [90885], [44290], [21887], [3837], [99360], [44290], [100554], [57218], [100087], [99441], [36885], [27773], [48921], [32664], [50511], [3837], [31914], [46451], [22243], [74413], [44290], [100554], [24339], [9370], [38182], [100554], [48921], [39165], [52129], [46448], [33108], [99867], [24339], [9370], [100554], [39165], [41146], [100426], [52129], [46448], [1773]], 'attention_mask': [[1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1]]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize_function(ds['train'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f4e42653",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets = ds.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    num_proc=100,\n",
    "    remove_columns=column_names,\n",
    "    load_from_cache_file=True,\n",
    "    desc=\"Running tokenizer on dataset\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "079b8fd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask'],\n",
       "        num_rows: 13000000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a3a8d35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[18493,\n",
       " 106416,\n",
       " 100226,\n",
       " 29767,\n",
       " 109742,\n",
       " 105223,\n",
       " 107717,\n",
       " 101995,\n",
       " 15946,\n",
       " 3837,\n",
       " 104495,\n",
       " 102031,\n",
       " 117743,\n",
       " 99337,\n",
       " 99990,\n",
       " 84088,\n",
       " 61191,\n",
       " 33108,\n",
       " 84088,\n",
       " 68153,\n",
       " 102170,\n",
       " 9370,\n",
       " 104585,\n",
       " 33108,\n",
       " 54542,\n",
       " 1773,\n",
       " 18493,\n",
       " 100768,\n",
       " 84088,\n",
       " 68153,\n",
       " 102170,\n",
       " 13343,\n",
       " 3837,\n",
       " 111343,\n",
       " 44063,\n",
       " 117743,\n",
       " 99337,\n",
       " 99990,\n",
       " 84088,\n",
       " 61191,\n",
       " 100630,\n",
       " 18493,\n",
       " 31843,\n",
       " 94432,\n",
       " 104270,\n",
       " 3837,\n",
       " 118603,\n",
       " 15946,\n",
       " 47606,\n",
       " 100065,\n",
       " 110691,\n",
       " 8997,\n",
       " 101114,\n",
       " 106509,\n",
       " 100040,\n",
       " 62926,\n",
       " 3837,\n",
       " 91676,\n",
       " 100768,\n",
       " 84088,\n",
       " 68153,\n",
       " 102170,\n",
       " 13343,\n",
       " 100630,\n",
       " 117743,\n",
       " 99337,\n",
       " 99990,\n",
       " 84088,\n",
       " 61191,\n",
       " 59217,\n",
       " 101114,\n",
       " 106509,\n",
       " 118266,\n",
       " 3837,\n",
       " 91676,\n",
       " 100768,\n",
       " 84088,\n",
       " 68153,\n",
       " 102170,\n",
       " 13343,\n",
       " 103869,\n",
       " 20755,\n",
       " 117743,\n",
       " 99337,\n",
       " 99990,\n",
       " 84088,\n",
       " 61191,\n",
       " 1773,\n",
       " 101042,\n",
       " 105073,\n",
       " 3837,\n",
       " 85106,\n",
       " 60610,\n",
       " 117743,\n",
       " 99337,\n",
       " 99990,\n",
       " 84088,\n",
       " 61191,\n",
       " 57218,\n",
       " 84088,\n",
       " 68153,\n",
       " 102170,\n",
       " 101920,\n",
       " 102021,\n",
       " 100145,\n",
       " 8997,\n",
       " 21887,\n",
       " 79766,\n",
       " 43288,\n",
       " 110566,\n",
       " 104186,\n",
       " 100145,\n",
       " 3837,\n",
       " 101140,\n",
       " 85106,\n",
       " 99794,\n",
       " 109742,\n",
       " 107402,\n",
       " 33108,\n",
       " 41146,\n",
       " 99990,\n",
       " 100837,\n",
       " 100674,\n",
       " 1773,\n",
       " 109742,\n",
       " 105599,\n",
       " 45943,\n",
       " 9909,\n",
       " 105020,\n",
       " 5373,\n",
       " 47874,\n",
       " 49567,\n",
       " 7552,\n",
       " 18493,\n",
       " 110676,\n",
       " 101925,\n",
       " 102710,\n",
       " 101720,\n",
       " 61191,\n",
       " 100622,\n",
       " 37643,\n",
       " 84088,\n",
       " 104282,\n",
       " 68536,\n",
       " 107374,\n",
       " 104491,\n",
       " 110676,\n",
       " 84088,\n",
       " 1773,\n",
       " 17714,\n",
       " 101153,\n",
       " 105444,\n",
       " 99543,\n",
       " 84088,\n",
       " 96050,\n",
       " 109742,\n",
       " 15946,\n",
       " 47606,\n",
       " 99990,\n",
       " 100837,\n",
       " 109658,\n",
       " 100674,\n",
       " 8997,\n",
       " 100141,\n",
       " 102018,\n",
       " 3837,\n",
       " 99886,\n",
       " 107118,\n",
       " 99304,\n",
       " 106600,\n",
       " 9370,\n",
       " 84088,\n",
       " 61191,\n",
       " 3837,\n",
       " 99886,\n",
       " 106733,\n",
       " 99304,\n",
       " 73670,\n",
       " 32664,\n",
       " 105004,\n",
       " 84088,\n",
       " 61191,\n",
       " 71817,\n",
       " 99990,\n",
       " 100837,\n",
       " 8997,\n",
       " 32664,\n",
       " 109742,\n",
       " 100141,\n",
       " 110339,\n",
       " 99883,\n",
       " 3837,\n",
       " 41146,\n",
       " 77172,\n",
       " 41299,\n",
       " 105020,\n",
       " 5373,\n",
       " 47874,\n",
       " 49567,\n",
       " 101094,\n",
       " 109742,\n",
       " 105223,\n",
       " 107717,\n",
       " 3837,\n",
       " 107717,\n",
       " 101913,\n",
       " 84088,\n",
       " 61191,\n",
       " 20412,\n",
       " 117743,\n",
       " 84088,\n",
       " 61191,\n",
       " 8997,\n",
       " 41146,\n",
       " 105216,\n",
       " 105020,\n",
       " 5373,\n",
       " 47874,\n",
       " 49567,\n",
       " 3837,\n",
       " 69041,\n",
       " 103946,\n",
       " 23384,\n",
       " 116977,\n",
       " 109742,\n",
       " 105223,\n",
       " 107717,\n",
       " 3837,\n",
       " 107717,\n",
       " 9370,\n",
       " 84088,\n",
       " 61191,\n",
       " 20412,\n",
       " 91453,\n",
       " 47882,\n",
       " 84088,\n",
       " 61191,\n",
       " 8997,\n",
       " 100141,\n",
       " 104705,\n",
       " 3837,\n",
       " 91453,\n",
       " 47882,\n",
       " 84088,\n",
       " 61191,\n",
       " 99536,\n",
       " 85336,\n",
       " 117743,\n",
       " 84088,\n",
       " 61191,\n",
       " 9370,\n",
       " 80094,\n",
       " 20412,\n",
       " 50511,\n",
       " 103311,\n",
       " 61191,\n",
       " 3837,\n",
       " 99304,\n",
       " 100345,\n",
       " 50511,\n",
       " 103311,\n",
       " 61191,\n",
       " 59879,\n",
       " 22704,\n",
       " 104664,\n",
       " 103311,\n",
       " 8997,\n",
       " 102460,\n",
       " 85106,\n",
       " 99794,\n",
       " 117743,\n",
       " 99337,\n",
       " 99990,\n",
       " 84088,\n",
       " 61191,\n",
       " 107402,\n",
       " 81217,\n",
       " 100394,\n",
       " 99917,\n",
       " 8997,\n",
       " 18493,\n",
       " 100768,\n",
       " 91453,\n",
       " 47882,\n",
       " 84088,\n",
       " 61191,\n",
       " 33108,\n",
       " 117743,\n",
       " 84088,\n",
       " 61191,\n",
       " 9370,\n",
       " 99572,\n",
       " 61191,\n",
       " 13343,\n",
       " 3837,\n",
       " 104685,\n",
       " 105609,\n",
       " 99393,\n",
       " 8863,\n",
       " 3837,\n",
       " 91676,\n",
       " 39165,\n",
       " 22704,\n",
       " 117743,\n",
       " 84088,\n",
       " 61191,\n",
       " 107043,\n",
       " 39165,\n",
       " 22704,\n",
       " 91453,\n",
       " 47882,\n",
       " 84088,\n",
       " 61191,\n",
       " 1773,\n",
       " 99487,\n",
       " 99572,\n",
       " 61191,\n",
       " 18493,\n",
       " 39165,\n",
       " 22704,\n",
       " 38342,\n",
       " 101884,\n",
       " 99990,\n",
       " 100837,\n",
       " 3837,\n",
       " 17714,\n",
       " 117743,\n",
       " 99337,\n",
       " 99990,\n",
       " 84088,\n",
       " 61191,\n",
       " 96050,\n",
       " 103934,\n",
       " 110339,\n",
       " 18830,\n",
       " 91453,\n",
       " 47882,\n",
       " 84088,\n",
       " 61191,\n",
       " 13343,\n",
       " 87256,\n",
       " 71817,\n",
       " 99990,\n",
       " 100837,\n",
       " 8997,\n",
       " 99304,\n",
       " 100394,\n",
       " 117743,\n",
       " 99337,\n",
       " 99990,\n",
       " 84088,\n",
       " 61191,\n",
       " 104396,\n",
       " 107711,\n",
       " 41146,\n",
       " 117743,\n",
       " 84088,\n",
       " 61191,\n",
       " 33108,\n",
       " 91453,\n",
       " 47882,\n",
       " 84088,\n",
       " 61191,\n",
       " 20450,\n",
       " 101913,\n",
       " 16530,\n",
       " 101266,\n",
       " 8997,\n",
       " 77557,\n",
       " 3837,\n",
       " 99304,\n",
       " 104533,\n",
       " 101096,\n",
       " 102049,\n",
       " 105020,\n",
       " 106510,\n",
       " 3837,\n",
       " 99716,\n",
       " 26288,\n",
       " 3837,\n",
       " 91453,\n",
       " 47882,\n",
       " 114864,\n",
       " 102617,\n",
       " 117743,\n",
       " 114864,\n",
       " 49567,\n",
       " 8997,\n",
       " 45181,\n",
       " 84088,\n",
       " 68153,\n",
       " 99990,\n",
       " 100837,\n",
       " 106413,\n",
       " 50930,\n",
       " 3837,\n",
       " 117743,\n",
       " 99337,\n",
       " 99990,\n",
       " 84088,\n",
       " 61191,\n",
       " 100009,\n",
       " 77172,\n",
       " 41299,\n",
       " 9370,\n",
       " 113964,\n",
       " 117743,\n",
       " 84088,\n",
       " 61191,\n",
       " 113965,\n",
       " 109742,\n",
       " 50511,\n",
       " 103311,\n",
       " 61191,\n",
       " 9370,\n",
       " 100768,\n",
       " 101925,\n",
       " 3837,\n",
       " 100131,\n",
       " 41146,\n",
       " 110019,\n",
       " 117743,\n",
       " 84088,\n",
       " 61191,\n",
       " 99990,\n",
       " 100837,\n",
       " 108936,\n",
       " 100690,\n",
       " 101884,\n",
       " 3837,\n",
       " 100141,\n",
       " 30534,\n",
       " 106200,\n",
       " 41146,\n",
       " 100353,\n",
       " 18830,\n",
       " 105004,\n",
       " 91453,\n",
       " 47882,\n",
       " 84088,\n",
       " 61191,\n",
       " 13343,\n",
       " 3837,\n",
       " 101901,\n",
       " 100690,\n",
       " 101884,\n",
       " 117743,\n",
       " 84088,\n",
       " 61191,\n",
       " 99990,\n",
       " 100837,\n",
       " 8997,\n",
       " 101479,\n",
       " 3837,\n",
       " 117743,\n",
       " 99337,\n",
       " 99990,\n",
       " 84088,\n",
       " 61191,\n",
       " 101199,\n",
       " 103486,\n",
       " 44091,\n",
       " 3837,\n",
       " 105095,\n",
       " 99990,\n",
       " 100837,\n",
       " 100683,\n",
       " 99555,\n",
       " 100741,\n",
       " 99564,\n",
       " 3837,\n",
       " 77557,\n",
       " 99304,\n",
       " 99881,\n",
       " 112788,\n",
       " 3837,\n",
       " 80443,\n",
       " 91453,\n",
       " 47882,\n",
       " 84088,\n",
       " 61191,\n",
       " 3837,\n",
       " 104616,\n",
       " 117743,\n",
       " 99337,\n",
       " 99990,\n",
       " 84088,\n",
       " 61191,\n",
       " 80158,\n",
       " 101068,\n",
       " 101884,\n",
       " 99990,\n",
       " 100837,\n",
       " 1773,\n",
       " 109605,\n",
       " 99304,\n",
       " 101892,\n",
       " 105870,\n",
       " 100138,\n",
       " 99812,\n",
       " 101915,\n",
       " 117743,\n",
       " 99337,\n",
       " 99990,\n",
       " 117102,\n",
       " 3837,\n",
       " 117743,\n",
       " 84088,\n",
       " 61191,\n",
       " 99990,\n",
       " 100837,\n",
       " 80158,\n",
       " 103571,\n",
       " 101884,\n",
       " 8997,\n",
       " 100161,\n",
       " 85106,\n",
       " 99794,\n",
       " 84088,\n",
       " 68153,\n",
       " 102170,\n",
       " 107402,\n",
       " 8997,\n",
       " 84088,\n",
       " 68153,\n",
       " 102170,\n",
       " 3837,\n",
       " 102119,\n",
       " 104442,\n",
       " 62112,\n",
       " 100226,\n",
       " 29767,\n",
       " 109742,\n",
       " 105223,\n",
       " 107717,\n",
       " 3837,\n",
       " 100673,\n",
       " 99599,\n",
       " 84088,\n",
       " 68153,\n",
       " 114645,\n",
       " 100631,\n",
       " 108862,\n",
       " 9370,\n",
       " 80094,\n",
       " 1773,\n",
       " 101888,\n",
       " 84088,\n",
       " 68153,\n",
       " 102170,\n",
       " 3837,\n",
       " 118603,\n",
       " 105656,\n",
       " 101312,\n",
       " 112926,\n",
       " 8997,\n",
       " 77557,\n",
       " 3837,\n",
       " 109885,\n",
       " 24339,\n",
       " 101085,\n",
       " 102040,\n",
       " 100348,\n",
       " 99355,\n",
       " 99584,\n",
       " 99798,\n",
       " 107582,\n",
       " 100226,\n",
       " 29767,\n",
       " 101070,\n",
       " 100775,\n",
       " 99670,\n",
       " 101090,\n",
       " 99599,\n",
       " 84088,\n",
       " 68153,\n",
       " 102170,\n",
       " 3837,\n",
       " 101043,\n",
       " 100152,\n",
       " 107717,\n",
       " 99990,\n",
       " 100837,\n",
       " 13343,\n",
       " 104674,\n",
       " 101090,\n",
       " 99599,\n",
       " 84088,\n",
       " 68153,\n",
       " 102170,\n",
       " 1773,\n",
       " 100351,\n",
       " 99807,\n",
       " 49567,\n",
       " 30868,\n",
       " 99610,\n",
       " 9370,\n",
       " 26940,\n",
       " 100226,\n",
       " 29767,\n",
       " 109742,\n",
       " 105223,\n",
       " 107717,\n",
       " 102206,\n",
       " 104341,\n",
       " 101313,\n",
       " 33108,\n",
       " 102206,\n",
       " 106637,\n",
       " 25067,\n",
       " 14777,\n",
       " 107729,\n",
       " 104496,\n",
       " 36987,\n",
       " 89012,\n",
       " 99599,\n",
       " 84088,\n",
       " 68153,\n",
       " 101090,\n",
       " 102170,\n",
       " 9370,\n",
       " 110902,\n",
       " 3837,\n",
       " 101359,\n",
       " 99486,\n",
       " 114645,\n",
       " 18158,\n",
       " 9370,\n",
       " 99599,\n",
       " 84088,\n",
       " 68153,\n",
       " 18493,\n",
       " 108820,\n",
       " 112080,\n",
       " 103982,\n",
       " 101068,\n",
       " 99626,\n",
       " 18397,\n",
       " 107625,\n",
       " 32945,\n",
       " 198,\n",
       " 103959,\n",
       " 79766,\n",
       " 55135,\n",
       " 57218,\n",
       " 99445,\n",
       " 45629,\n",
       " 100885,\n",
       " 39762,\n",
       " 99610,\n",
       " 9370,\n",
       " 26940,\n",
       " 109742,\n",
       " 105223,\n",
       " 107717,\n",
       " 100226,\n",
       " 29767,\n",
       " 9370,\n",
       " 112983,\n",
       " 57218,\n",
       " 104332,\n",
       " 25067,\n",
       " 14777,\n",
       " 107729,\n",
       " 104496,\n",
       " 36987,\n",
       " 104341,\n",
       " 107933,\n",
       " 3837,\n",
       " 99204,\n",
       " 94444,\n",
       " 23384,\n",
       " 11622,\n",
       " 100226,\n",
       " 29767,\n",
       " 9370,\n",
       " 109742,\n",
       " 105223,\n",
       " 107717,\n",
       " 104744,\n",
       " 99990,\n",
       " 100837,\n",
       " 9370,\n",
       " 84088,\n",
       " 68153,\n",
       " 3837,\n",
       " 101982,\n",
       " 100673,\n",
       " 99204,\n",
       " 94444,\n",
       " 23384,\n",
       " 50511,\n",
       " 103311,\n",
       " 61191,\n",
       " 9370,\n",
       " 101940,\n",
       " 20412,\n",
       " 102082,\n",
       " 31838,\n",
       " 104585,\n",
       " 9370,\n",
       " 99599,\n",
       " 84088,\n",
       " 68153,\n",
       " 108862,\n",
       " 9370,\n",
       " 80094,\n",
       " 32945,\n",
       " 198,\n",
       " 45181,\n",
       " 100001,\n",
       " 112926,\n",
       " 101479,\n",
       " 3837,\n",
       " 84088,\n",
       " 68153,\n",
       " 102170,\n",
       " 104583,\n",
       " 99912,\n",
       " 105998,\n",
       " 102170,\n",
       " 3837,\n",
       " 109706,\n",
       " 100630,\n",
       " 103486,\n",
       " 107625,\n",
       " 8545,\n",
       " 117743,\n",
       " 99337,\n",
       " 99990,\n",
       " 84088,\n",
       " 61191,\n",
       " 3837,\n",
       " 117743,\n",
       " 99337,\n",
       " 99990,\n",
       " 84088,\n",
       " 61191,\n",
       " 57218,\n",
       " 84088,\n",
       " 68153,\n",
       " 102170,\n",
       " 101920,\n",
       " 53153,\n",
       " 101041,\n",
       " 54623,\n",
       " 49567,\n",
       " 17992,\n",
       " 8997,\n",
       " 99611,\n",
       " 17447,\n",
       " 101042,\n",
       " 3837,\n",
       " 117743,\n",
       " 99337,\n",
       " 99990,\n",
       " 84088,\n",
       " 61191,\n",
       " 3837,\n",
       " 100009,\n",
       " 32555,\n",
       " 99599,\n",
       " 84088,\n",
       " 68153,\n",
       " 101199,\n",
       " 87267,\n",
       " 99250,\n",
       " 99990,\n",
       " 100837,\n",
       " 106293,\n",
       " 3837,\n",
       " 104485,\n",
       " 100690,\n",
       " 101090,\n",
       " 99599,\n",
       " 84088,\n",
       " 68153,\n",
       " 108862,\n",
       " 3837,\n",
       " 100141,\n",
       " 104705,\n",
       " 50511,\n",
       " 105278,\n",
       " 45181,\n",
       " 84088,\n",
       " 68153,\n",
       " 102170,\n",
       " 15946,\n",
       " 118266,\n",
       " 3837,\n",
       " 101167,\n",
       " 107219,\n",
       " 105278,\n",
       " 100040,\n",
       " 62926,\n",
       " 17254,\n",
       " 84088,\n",
       " 68153,\n",
       " 102170,\n",
       " 8997,\n",
       " 77557,\n",
       " 3837,\n",
       " 39165,\n",
       " 110339,\n",
       " 112895,\n",
       " 101892,\n",
       " 105870,\n",
       " 100138,\n",
       " 99812,\n",
       " 101915,\n",
       " 117743,\n",
       " 99337,\n",
       " 99990,\n",
       " 84088,\n",
       " 61191,\n",
       " 117102,\n",
       " 33447,\n",
       " 3837,\n",
       " 101063,\n",
       " 84088,\n",
       " 68153,\n",
       " 102170,\n",
       " 104347,\n",
       " 45181,\n",
       " 104264,\n",
       " 44091,\n",
       " 101548,\n",
       " 12857,\n",
       " 102672,\n",
       " 59151,\n",
       " 3837,\n",
       " 106436,\n",
       " 30534,\n",
       " 44063,\n",
       " 101063,\n",
       " 117743,\n",
       " 99337,\n",
       " 99990,\n",
       " 84088,\n",
       " 61191,\n",
       " 62926,\n",
       " 17254,\n",
       " 84088,\n",
       " 68153,\n",
       " 102170,\n",
       " 8997,\n",
       " 99999,\n",
       " 96050,\n",
       " 100226,\n",
       " 29767,\n",
       " 109742,\n",
       " 105223,\n",
       " 107717,\n",
       " 101995,\n",
       " 15946,\n",
       " 3837,\n",
       " 100141,\n",
       " 104705,\n",
       " 3837,\n",
       " 62244,\n",
       " 23031,\n",
       " 103311,\n",
       " 103947,\n",
       " 117743,\n",
       " 84088,\n",
       " 61191,\n",
       " 100622,\n",
       " 84088,\n",
       " 68153,\n",
       " 102170,\n",
       " 9370,\n",
       " 100768,\n",
       " 115775,\n",
       " 96050,\n",
       " 118738,\n",
       " 110477,\n",
       " 57191,\n",
       " 101665,\n",
       " 102520,\n",
       " 13343,\n",
       " 3837,\n",
       " 50511,\n",
       " 99360,\n",
       " 117743,\n",
       " 99337,\n",
       " 99990,\n",
       " 84088,\n",
       " 61191,\n",
       " 45181,\n",
       " 84088,\n",
       " 68153,\n",
       " 102170,\n",
       " 15946,\n",
       " 103869,\n",
       " 20755,\n",
       " 3837,\n",
       " 77288,\n",
       " 110339,\n",
       " 101915,\n",
       " 117743,\n",
       " 99337,\n",
       " 99990,\n",
       " 117102,\n",
       " 9370,\n",
       " 110953,\n",
       " 1773,\n",
       " 99654,\n",
       " 54542,\n",
       " 3837,\n",
       " 99360,\n",
       " 102520,\n",
       " 57218,\n",
       " 102672,\n",
       " 59151,\n",
       " 101162,\n",
       " 50511,\n",
       " 3837,\n",
       " 101257,\n",
       " 110477,\n",
       " 24339,\n",
       " 9370,\n",
       " 38182,\n",
       " 100554,\n",
       " 102084,\n",
       " 100808,\n",
       " 33108,\n",
       " 111849,\n",
       " 9370,\n",
       " 100554,\n",
       " 39165,\n",
       " 41146,\n",
       " 100426,\n",
       " 100808,\n",
       " 1773]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets['train'][0]['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f342d8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "\n",
    "block_size=2048\n",
    "def group_texts(examples):\n",
    "    concatenated_examples = {k: list(chain(*examples[k])) for k in examples.keys()}\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    if total_length >= block_size:\n",
    "        total_length = (total_length // block_size) * block_size\n",
    "    \n",
    "    result = {\n",
    "        k: [t[i:i+block_size] for i in range(0, total_length, block_size)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    result['labels'] = result[\"input_ids\"].copy()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf4c71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_datasets = tokenized_datasets.map(\n",
    "    group_texts,\n",
    "    batched=True,\n",
    "    num_proc=100,\n",
    "    load_from_cache_file=True,\n",
    "    desc = f'Grouping text in chunks of {block_size}',\n",
    "    batch_size=40000,\n",
    ")\n",
    "train_dataset = lm_datasets[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c8f8a402",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='output',\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=4,\n",
    "    logging_steps=10,\n",
    "    num_train_epochs=1,\n",
    "    save_steps=100,\n",
    "    learning_rate=1e-4,\n",
    "    gradient_checkpointing=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce9fdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, default_data_collator\n",
    "from torchdata.datapipes.iter import IterableWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be994dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=IterableWrapper(train_dataset),\n",
    "    eval_dataset=None,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=default_data_collator\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05265685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0+cu129\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca0b63a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zhd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
